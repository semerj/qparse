{
 "metadata": {
  "name": "",
  "signature": "sha256:3f9a71fb74cffca1c199f23a8d116393a43b58021cb81b9c6161d2d42b2e8cd3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "import nltk\n",
      "import re\n",
      "from collections import Counter\n",
      "from nltk import ne_chunk, pos_tag, word_tokenize\n",
      "from nltk import RegexpParser\n",
      "import nltk.chunk\n",
      "import itertools\n",
      "from nltk.tokenize import sent_tokenize\n",
      "import nltk.text\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "pd.set_option('max_columns', 50)\n",
      "from pandas.io import sql\n",
      "import functools\n",
      "import operator\n",
      "from functools import partial\n",
      "from nltk import ne_chunk, pos_tag, word_tokenize\n",
      "from nltk import RegexpParser\n",
      "import nltk.chunk\n",
      "import itertools\n",
      "from nltk.tokenize import sent_tokenize\n",
      "import nltk.text\n",
      "from functools import partial\n",
      "from string import punctuation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import ast\n",
      "import csv\n",
      "import itertools\n",
      "from nltk import RegexpParser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('all_sentences_tagged_indexed__complete.csv', index_col=0,\n",
      "                 dtype={'story_id': int, 'para_index': int, 'tagged_sent': object, 'quote_in_para': object})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Read CSV as Dict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_dict = []\n",
      "with open('all_sentences_tagged_indexed__complete.csv') as csvfile:\n",
      "    reader = csv.DictReader(csvfile)\n",
      "    for key, row in enumerate(reader):\n",
      "        data = {}\n",
      "        data['sent_index'] = key\n",
      "        data['story_id'] = int(row['story_id'])\n",
      "        data['para_index'] = int(row['para_index'])\n",
      "        data['tagged_sent'] = ast.literal_eval(row['tagged_sent'])\n",
      "        data['quote_in_para'] = row['quote_in_para']\n",
      "        df_dict.append(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### One document"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_13661 = []\n",
      "for data in df_dict:\n",
      "    if data['story_id'] == 13661:\n",
      "        df_13661.append(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def group_dict_func(list_of_dicts):\n",
      "    keyfunc = lambda x: x['para_index']\n",
      "    groups = []\n",
      "    data = sorted(list_of_dicts, key=keyfunc)\n",
      "    for k, g in itertools.groupby(data, key=keyfunc):\n",
      "        groups.append(list(g))\n",
      "\n",
      "    para_dict_list = []\n",
      "    for g in groups:\n",
      "        para_dict = {}\n",
      "        para_dict['tagged_sent'] = []\n",
      "        for l in g:\n",
      "            para_dict['para_index'] = l['para_index']\n",
      "            para_dict['quote_in_para'] = l['quote_in_para']\n",
      "            para_dict['story_id'] = l['story_id']\n",
      "            para_dict['tagged_sent'].append(l['tagged_sent'])\n",
      "        para_dict_list.append(para_dict)\n",
      "    \n",
      "    return para_dict_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "para_dict_13661 = group_dict_func(df_13661)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "last_para_index = len(para_dict_13661) - 1\n",
      "for d in para_dict_13661:\n",
      "    # if any tagged sentences contain said, set feature equal to list of sents\n",
      "    tagged_sent_list = [s for s in d['tagged_sent']]\n",
      "    for tup in tuplist:\n",
      "        match_sent = [tup for text, pos in tup if text in ['said', 'Said']]\n",
      "        d['feature_said_text'] = match_sent\n",
      "    \n",
      "    if d['para_index'] == 0 and d['quote_in_para'] == 1:\n",
      "        print \"1st paragraph, don't look back\"\n",
      "        \n",
      "    elif d['para_index'] == last_para_index and d['quote_in_para'] == 1:\n",
      "        print \"Last paragraph, don't look forward\"\n",
      "\n",
      "    elif d['quote_in_para'] == 1:\n",
      "        print \"Middle paragraph\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dont look back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "can look forward and back\n",
        "dont look forward\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tuplist = [s for s in para_dict_13661[0]['tagged_sent']]\n",
      "for tup in tuplist:\n",
      "    matches = [tup for text, pos in tup if text == 'the']\n",
      "    if matches:\n",
      "        print matches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(u'A', u'DT'), (u'handful', u'NN'), (u'of', u'IN'), (u'beach', u'NN'), (u'lovers', u'NNS'), (u'and', u'CC'), (u'staff', u'NN'), (u'at', u'IN'), (u'McGrath', u'NNP'), (u'State', u'NNP'), (u'Beach', u'NNP'), (u'near', u'IN'), (u'Ventura', u'NNP'), (u'raised', u'VBD'), (u'half', u'PDT'), (u'a', u'DT'), (u'million', u'CD'), (u'dollars', u'NNS'), (u'for', u'IN'), (u'the', u'DT'), (u'new', u'JJ'), (u'sewage', u'NN'), (u'system', u'NN'), (u'that', u'WDT'), (u'is', u'VBZ'), (u'keeping', u'VBG'), (u'that', u'IN'), (u'park', u'NN'), (u'open', u'JJ'), (u'.', u'.')]]\n",
        "[[(u'And', u'CC'), (u'a', u'DT'), (u'nonprofit', u'JJ'), (u',', u','), (u'the', u'DT'), (u'Coe', u'NNP'), (u'Park', u'NNP'), (u'Preservation', u'NNP'), (u'Fund', u'NNP'), (u',', u','), (u'raised', u'VBD'), (u'more', u'JJR'), (u'than', u'IN'), (u'a', u'DT'), (u'million', u'CD'), (u'dollars', u'NNS'), (u'to', u'TO'), (u'protect', u'VB'), (u'its', u'PRP$'), (u'namesake', u'NN'), (u'park', u'NN'), (u'near', u'IN'), (u'San', u'NNP'), (u'Jose', u'NNP'), (u'.', u'.')]]\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "person_said_rule = '''\n",
      "QT:\n",
      "    { (<``>|<\\'\\'>)+ <.*>+ (<''>|<\\'\\'>)+ <.*>+ }\n",
      "    } (<``>|<\\'\\'>)+ <.*>+ (<''>|<\\'\\'>) {\n",
      "    { <VB>+ <DT>?<NNP>+<JJ.*>*<RB>? <JJ.*>*<NN.*|CD>* }\n",
      "    } <VB.*> {\n",
      "'''\n",
      "quote_rule = '''\n",
      "QUOTE:\n",
      "    { (<``>|<\\'\\'>)+ <.*>+ (<''>|<\\'\\'>) }\n",
      "    '''\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in para_dict_13661:\n",
      "    sents = p['tagged_sent']\n",
      "    cp = RegexpParser(quote_rule)\n",
      "    for sent in sents:\n",
      "        tree = cp.parse(sent)\n",
      "        for subtree in tree.subtrees():\n",
      "            if subtree.label() == 'QUOTE': \n",
      "                print subtree\n",
      "                #words =  [word[0] for word in subtree]\n",
      "                #words = \" \".join(words)\n",
      "                #print words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(QUOTE\n",
        "  ``/``\n",
        "  People/NNS\n",
        "  are/VBP\n",
        "  beginning/VBG\n",
        "  to/TO\n",
        "  be/VB\n",
        "  mobilized/VBN\n",
        "  in/IN\n",
        "  a/DT\n",
        "  way/NN\n",
        "  they/PRP\n",
        "  have/VBP\n",
        "  n't/RB\n",
        "  before/RB\n",
        "  ,/,\n",
        "  ''/'')\n",
        "(QUOTE\n",
        "  ``/``\n",
        "  do/VB\n",
        "  everything/NN\n",
        "  I/PRP\n",
        "  can/MD\n",
        "  to/TO\n",
        "  help/VB\n",
        "  keep/VB\n",
        "  parks/NNS\n",
        "  open/JJ\n",
        "  ./.\n",
        "  ''/'')\n",
        "(QUOTE\n",
        "  ``/``\n",
        "  but/CC\n",
        "  that/DT\n",
        "  does/VBZ\n",
        "  n't/RB\n",
        "  mean/VB\n",
        "  you/PRP\n",
        "  should/MD\n",
        "  pay/VB\n",
        "  the/DT\n",
        "  same/JJ\n",
        "  amount/NN\n",
        "  to/TO\n",
        "  camp/NN\n",
        "  on/IN\n",
        "  July/NNP\n",
        "  4th/JJ\n",
        "  as/IN\n",
        "  you/PRP\n",
        "  would/MD\n",
        "  on/IN\n",
        "  January/NNP\n",
        "  4th/JJ\n",
        "  ./.\n",
        "  ''/'')\n",
        "(QUOTE\n",
        "  ``/``\n",
        "  We/PRP\n",
        "  'd/MD\n",
        "  start/VB\n",
        "  by/IN\n",
        "  bringing/VBG\n",
        "  out/RP\n",
        "  kids/NNS\n",
        "  from/IN\n",
        "  every/DT\n",
        "  single/JJ\n",
        "  school/NN\n",
        "  in/IN\n",
        "  Santa/NNP\n",
        "  Rosa/NNP\n",
        "  within/IN\n",
        "  walking/VBG\n",
        "  distance/NN\n",
        "  ,/,\n",
        "  ''/'')\n",
        "(QUOTE\n",
        "  ``/``\n",
        "  While/IN\n",
        "  some/DT\n",
        "  ranger/NN\n",
        "  duties/NNS\n",
        "  ,/,\n",
        "  such/JJ\n",
        "  as/IN\n",
        "  responding/VBG\n",
        "  to/TO\n",
        "  emergencies/NNS\n",
        "  and/CC\n",
        "  making/VBG\n",
        "  arrests/NNS\n",
        "  ,/,\n",
        "  require/VBP\n",
        "  peace/NN\n",
        "  officer/NN\n",
        "  status/NN\n",
        "  ,/,\n",
        "  many/JJ\n",
        "  of/IN\n",
        "  them/PRP\n",
        "  do/VBP\n",
        "  not/RB\n",
        "  -LRB-/-LRB-\n",
        "  such/JJ\n",
        "  as/IN\n",
        "  managing/VBG\n",
        "  staff/NN\n",
        "  ,/,\n",
        "  providing/VBG\n",
        "  information/NN\n",
        "  to/TO\n",
        "  visitors/NNS\n",
        "  ,/,\n",
        "  and/CC\n",
        "  leading/VBG\n",
        "  school/NN\n",
        "  groups/NNS\n",
        "  on/IN\n",
        "  tours/NNS\n",
        "  -RRB-/-RRB-\n",
        "  ./.\n",
        "  ''/'')\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}