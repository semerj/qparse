{
 "metadata": {
  "gist_id": "4049e6edc0aff4b1a662",
  "name": "",
  "signature": "sha256:f8dd8af92ffe3b78855e4426c7a46943a947d5fdbb5f21df2e922132d44d8268"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Start up tasks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk, cPickle as pickle, codecs, re\n",
      "from nltk.corpus import brown, stopwords\n",
      "from string import punctuation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading corpora for analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown_news_raw = nltk.corpus.brown.sents(categories=\"news\")\n",
      "trial_desc = pickle.load(open('tagged_text_stanford.pickle','rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Making stopwords a set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopset = set(stopwords.words('english'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Text preparation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to parse text into sentences and tokenize those sentences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_text(rawtext):\n",
      "    '''\n",
      "    rawtext: string, such as that returned by Python's .read() method on files\n",
      "    '''\n",
      "    sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "    return [nltk.word_tokenize(s) for s in sent_tokenizer.tokenize(rawtext)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to parse and POS tag text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_tag_text(sents):\n",
      "    '''\n",
      "    sents: list of lists of strings, such as that returned by the parse_text function\n",
      "    '''\n",
      "    tagged_text = [nltk.pos_tag(s) for s in sents]\n",
      "    return tagged_text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Preprocessing corpora"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown_news = pos_tag_text(brown_news_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystery_text = pos_tag_text(parse_text(codecs.open('mystery.txt','r','utf-8').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Baseline model: n-gram frequencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to calculate the top ngrams for a given set of tagged sentences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ngram_calc(tagged_text, n, top=50, threshold=None):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    n: integer, desired n-grams\n",
      "    top: integer, number of n-grams to return\n",
      "    threshold: number, lowest frequency n-gram to return\n",
      "    '''\n",
      "    # get n-gram list and run frequency distribution\n",
      "    thesegrams = reduce(list.__add__,\n",
      "                        [nltk.util.ngrams([w for w, t in sent\n",
      "                                           if w[0] not in punctuation and not (len(w) > 5 and w.upper() == w)], n) \n",
      "                         for sent in tagged_text])\n",
      "    gramfreq = nltk.FreqDist(thesegrams)\n",
      "    \n",
      "    # output n-grams based on criteria\n",
      "    if not threshold:\n",
      "        return [(words, cnt) for words, cnt in gramfreq.items() \n",
      "                if words[0].lower() not in stopset and\n",
      "                   words[-1].lower() not in stopset and \n",
      "                   not any([re.search(r'''^[\\.,;\"'?():\\-_`]+$''',w) for w in words])][:top]\n",
      "    else:\n",
      "        return [(words, cnt) for words, cnt in gramfreq.items() \n",
      "                if words[0].lower() not in stopset and\n",
      "                   words[-1].lower() not in stopset and \n",
      "                   not any([re.search(r'''^[\\.,;\"'?():\\-_`]+$''',w) for w in words]) and \n",
      "                   cnt >= threshold]    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to calculate the best 2-, 3-, 4-, and 5-grams for a given set of tagged sentences, where no smaller n-gram can be wholly contained in a larger n-gram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def best_ngrams(tagged_text):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    '''\n",
      "    # initializing dictionary to contain the best n-grams\n",
      "    bestgrams = {}\n",
      "    \n",
      "    # going from 5-grams to bigrams, selecting those that occur somewhat frequently\n",
      "    for n in range(5,1,-1):\n",
      "        curgrams = ngram_calc(tagged_text, n, threshold = len(tagged_text) / (250.0 * n))\n",
      "        for words, cnt in curgrams:\n",
      "            # if current n-gram is not wholly contained in a larger n-gram, add to collection\n",
      "            if not any([' '.join(words) in ' '.join(b) for b in bestgrams.keys()]): bestgrams[words] = cnt\n",
      "    \n",
      "    return bestgrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wrapper procedure for printing the gist"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_ngram_gist(tagged_text):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    '''\n",
      "    top_ngrams = best_ngrams(tagged_text)\n",
      "    print '\\n'.join([' '.join(words) for words, cnt in sorted(top_ngrams.items(), key=lambda x: x[1] * len(x[0]), reverse=True)])[:2500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Writing gists"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_ngram_gist(trial_desc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "disease progression or unacceptable toxicity\n",
        "absence of disease progression\n",
        "quality of life\n",
        "patients will be accrued\n",
        "blood pressure\n",
        "et al\n",
        "patients treated with this regimen\n",
        "study treatment patients are followed\n",
        "completion of study treatment patients\n",
        "side effects\n",
        "breast cancer\n",
        "12 months\n",
        "accrued for this study within\n",
        "4 weeks\n",
        "Patients are stratified according\n",
        "Patients are randomized to 1\n",
        "purpose of this study\n",
        "multicenter study\n",
        "adverse events\n",
        "control group\n",
        "patients treated with these regimens\n",
        "clinical trial\n",
        "risk factors\n",
        "randomized to 1 of 2\n",
        "daily on days\n",
        "every 6 months\n",
        "pilot study\n",
        "informed consent\n",
        "bone marrow\n",
        "Patients receive oral\n",
        "1 of 2 treatment arms\n",
        "days 1\n",
        "heart failure\n",
        "response rate\n",
        "study drug\n",
        "take part in this study\n",
        "standard of care\n",
        "2 weeks\n",
        "randomized to receive\n",
        "IV over 1 hour\n",
        "maximum tolerated dose MTD\n",
        "regimen in these patients\n",
        "determine whether\n",
        "days in the absence\n",
        "health care\n",
        "group will receive\n",
        "physical activity\n",
        "Patients undergo\n",
        "6 weeks\n",
        "Arm II Patients receive\n",
        "patients will receive\n",
        "Arm I Patients receive\n",
        "twice daily\n",
        "patients treated with this drug\n",
        "one of two\n",
        "morbidity and mortality\n",
        "12 weeks\n",
        "randomized controlled trial\n",
        "24 hours\n",
        "8 weeks\n",
        "phase II\n",
        "study is to determine\n",
        "United States\n",
        "receive either\n",
        "drug in these patients\n",
        "IV over 30 minutes\n",
        "followed every 3 months\n",
        "two groups\n",
        "clinical trials\n",
        "heart disease\n",
        "tolerated dose MTD is determined\n",
        "immune response\n",
        "weight loss\n",
        "type 2 diabetes\n",
        "14 days\n",
        "stem cell\n",
        "minutes on day 1\n",
        "5 years\n",
        "Treatment repeats every 21 days\n",
        "Phase II\n",
        "primary outcome\n",
        "study is to evaluate\n",
        "patients undergoing\n",
        "years of age\n",
        "defined as the dose preceding\n",
        "7 days\n",
        "high risk\n",
        "Patients are followed every 3\n",
        "Quality of life is assessed\n",
        "et al.\n",
        "2 of 6 patients experience\n",
        "Courses repeat every\n",
        "randomized to one\n",
        "safety and tolerability\n",
        "blood samples\n",
        "every 3 weeks\n",
        "randomly assigned to receive\n",
        "randomly assigned to one\n",
        "months for 2 years\n",
        "study is designed\n",
        "minutes on days\n",
        "peripheral blood\n",
        "stem cells\n",
        "randomized double-blind\n",
        "safety and efficacy\n",
        "3 years\n",
        "Determine the maximum tolerated dose\n",
        "hours on days\n",
        "Patients also receive\n",
        "objective of this study\n",
        "patients will be randomized\n",
        "end of the study\n",
        "overall survival of patients treated\n",
        "pregnant women\n",
        "response in patients treated\n",
        "throughout the study\n",
        "test the hypothesis\n",
        "6 courses in the absence\n",
        "6 patients experience dose-limiting toxicity\n",
        "prostate cancer\n",
        "3 months for 1 year\n",
        "every 3 months for 1\n",
        "vitamin D\n",
        "myocardial infarction\n",
        "heart rate\n",
        "IV on days\n",
        "medical history\n",
        "evaluate the safety\n",
        "patients receive escalating doses\n",
        "progression-fr\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_ngram_gist(brown_news)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mr. and Mrs.\n",
        "New York\n",
        "per cent\n",
        "United States\n",
        "last year\n",
        "White House\n",
        "last week\n",
        "home runs\n",
        "U. S.\n",
        "President Kennedy\n",
        "last night\n",
        "years ago\n",
        "San Francisco\n",
        "Mr. Kennedy\n",
        "anti-trust laws\n",
        "Premier Khrushchev\n",
        "Kansas City\n",
        "high school\n",
        "Los Angeles\n",
        "New Orleans\n",
        "United Nations\n",
        "Secretary of State\n",
        "Mr. Hawksley said\n",
        "Mrs. Robert\n",
        "High School\n",
        "vice president\n",
        "sales tax\n",
        "American Catholic\n",
        "Mrs. John\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_ngram_gist(mystery_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "traders said\n",
        "U.S. Agriculture Department said\n",
        "company said\n",
        "interest rates\n",
        "officials said\n",
        "tonnes of free market barley\n",
        "said in a statement\n",
        "cts a gallon\n",
        "mln last month\n",
        "spokesman said\n",
        "USDA said\n",
        "analysts said\n",
        "Agreement on Tariffs and Trade\n",
        "Energy Information Administration EIA said\n",
        "price it charges contract barge\n",
        "TOKYO The Bank of Japan\n",
        "BANK OF JAPAN\n",
        "dlrs FOB Gulf\n",
        "oil companies\n",
        "International Coffee Organization ICO\n",
        "dlrs up 75 cts\n",
        "week ended March 27\n",
        "mln the EIA said\n",
        "week ended March 20\n",
        "pct of the area sown\n",
        "barge customers for heating oil\n",
        "Louvre accord\n",
        "said the dollar\n",
        "barrels in the week ended\n",
        "contract barge customers for heating\n",
        "mln a year ago\n",
        "charges contract barge customers\n",
        "Commodity Credit Corporation CCC\n",
        "25 pct\n",
        "General Agreement on Tariffs\n",
        "weekly petroleum status report\n",
        "mln a year earlier\n",
        "Saudi Arabia\n",
        "50 pct\n",
        "export quotas\n",
        "10 pct\n",
        "mln bushels\n",
        "Finance Minister Kiichi Miyazawa said\n",
        "cent a gallon effective today\n",
        "requested licences to export tonnes\n",
        "WEEK Distillate fuel stocks held\n",
        "York and at the close\n",
        "oil in New York harbor\n",
        "Japan the U.S. And West\n",
        "U.S. Agriculture Secretary Richard Lyng\n",
        "yen against in New York\n",
        "fuel stocks held in primary\n",
        "U.S. Treasury Secretary James Baker\n",
        "heating oil in New York\n",
        "stocks held in primary storage\n",
        "broadly consistent with economic fundamentals\n",
        "export tonnes of free market\n",
        "Exports in season\n",
        "sales of tonnes\n",
        "money supply growth\n",
        "dlrs up one dlr\n",
        "0.5 pct sulphur\n",
        "West Germany and Japan\n",
        "grade of unleaded gasoline\n",
        "around yen dealers said\n",
        "within ranges broadly consistent\n",
        "requested for a total\n",
        "yen against the dollar\n",
        "money market\n",
        "Finance Ministry\n",
        "said Japan\n",
        "wheat crop\n",
        "central banks\n",
        "Conger said\n",
        "told reporters\n",
        "mln bags\n",
        "one pct sulphur\n",
        "500 mln dlrs\n",
        "four mln barrels\n",
        "van Horick said\n",
        "International Monetary Fund\n",
        "ended December the sources said\n",
        "Bank of Japan intervened buying\n",
        "0.50 cent a gallon effective\n",
        "said India has targetted countries\n",
        "crude oil petroleum products chemicals\n",
        "make up only a small\n",
        "Thailand exported tonnes of rice\n",
        "Prime Minister Yasuhiro Nakasone said\n",
        "coffee jute engineering and electronic\n",
        "partners to help it cut\n",
        "dollar opened at yen\n",
        "Bank of Japan intervention\n",
        "senior ministry official said\n",
        "tonne FOB previous in brackets\n",
        "trade deficit and conserve foreign\n",
        "part of India total trading\n",
        "previous in brackets as follows\n",
        "pct from a year ago\n",
        "promote Indian exports a commerce\n",
        "MLN BU WHEAT 1,848 MLN\n",
        "likely to account for less\n",
        "jute engineering and electronic goods\n",
        "several weeks was not outside\n",
        "eight pct of the estimated\n",
        "told a Lower House Budget\n",
        "Si\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Chunking noun phrases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to chunk noun phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chunk_phrases(tagged_text):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    '''\n",
      "    # set up noun phrase grammar\n",
      "    grammar = \"\"\"\n",
      "                  NP: {(<NN.*><POS>)?<RB>?<JJ.*>*<NN.*|CD>+}\n",
      "            \"\"\"\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    \n",
      "    # initialize new list of sentences\n",
      "    new_sents = []\n",
      "    for sent in tagged_text:\n",
      "        # tag punctuation to remove it from chunker patterns\n",
      "        clean_sent = [(w, t if w[0] not in punctuation else 'XX') for w, t in sent]\n",
      "        new_sents.append([t if type(t) is tuple else (\" \".join([a for (a,b) in t.leaves()]), t.node) for t in cp.parse(clean_sent)])\n",
      "    \n",
      "    return new_sents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to chunk text and produce frequent noun phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def top_chunks(tagged_text, min_length=1):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    min_length: integer, minimum number of words to be considered a chunk\n",
      "    '''\n",
      "    # run chunker\n",
      "    chunked_text = chunk_phrases(tagged_text)\n",
      "    \n",
      "    # return frequent chunks\n",
      "    return nltk.FreqDist([w for sent in chunked_text for w, t in sent \n",
      "                          if t == 'NP' and len(w) - len(re.sub(' ','',w)) >= min_length - 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wrapper procedure for printing the gist"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_chunk_gist(tagged_text):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    '''\n",
      "    np_freq = top_chunks(tagged_text, 3)\n",
      "    print '\\n'.join([chunk for chunk, cnt in np_freq.items()])[:2500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Writing gists"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_chunk_gist(trial_desc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 treatment arms\n",
        "M. D. Anderson\n",
        "type 2 diabetes\n",
        "body mass index\n",
        "6 patients experience\n",
        "coronary heart disease\n",
        "congestive heart failure\n",
        "intolerable side effects\n",
        "magnetic resonance imaging\n",
        "two treatment arms\n",
        "type 2 diabetes mellitus\n",
        "objective response rate\n",
        "primary outcome measure\n",
        "coronary artery disease\n",
        "ischemic heart disease\n",
        "non-small cell lung cancer\n",
        "vascular endothelial growth factor\n",
        "cardiovascular risk factors\n",
        "high blood pressure\n",
        "metastatic breast cancer\n",
        "overall response rate\n",
        "phase II study\n",
        "red blood cells\n",
        "serious adverse events\n",
        "white blood cells\n",
        "clinical laboratory tests\n",
        "glomerular filtration rate\n",
        "high pressure phase\n",
        "breast cancer patients\n",
        "metastatic colorectal cancer\n",
        "minimal residual disease\n",
        "positron emission tomography\n",
        "sickle cell disease\n",
        "two treatment groups\n",
        "3 treatment arms\n",
        "Canadian CT Head Rule\n",
        "National Cancer Institute\n",
        "blood sample collection\n",
        "bone mineral density\n",
        "complete physical exam\n",
        "dose escalation study\n",
        "high risk patients\n",
        "least 6 months\n",
        "omega-3 fatty acids\n",
        "spinal cord injury\n",
        "Secondary outcome measures\n",
        "acute kidney injury\n",
        "acute myeloid leukemia\n",
        "acute myocardial infarction\n",
        "advanced solid tumors\n",
        "atorvastatin 10 mg\n",
        "calcium channel blockers\n",
        "chronic hepatitis C\n",
        "congenital heart disease\n",
        "controlled clinical trial\n",
        "critically ill patients\n",
        "diastolic blood pressure\n",
        "drug 3 times\n",
        "external beam radiotherapy\n",
        "major risk factor\n",
        "negative predictive value\n",
        "phase II portion\n",
        "squamous cell carcinoma\n",
        "stem cell transplant\n",
        "traumatic brain injury\n",
        "type 1 diabetes\n",
        "urine pregnancy test\n",
        "Canadian C-Spine Rule\n",
        "Howard University Hospital\n",
        "Study Drug Administration\n",
        "Type 2 diabetes\n",
        "Visual Analogue Scale\n",
        "acute lymphoblastic leukemia\n",
        "autologous stem cell transplantation\n",
        "central nervous system\n",
        "central venous catheter\n",
        "chronic lung disease\n",
        "high dose chemotherapy\n",
        "hydromorphone HCI IR\n",
        "least 3 months\n",
        "low birth weight\n",
        "magnetic resonance spectroscopy\n",
        "mild cognitive impairment\n",
        "next dose level\n",
        "phase I study\n",
        "positive predictive value\n",
        "renal replacement therapy\n",
        "telaprevir 750 mg\n",
        "three treatment arms\n",
        "ECOG performance status\n",
        "Specific Aim 1\n",
        "Specific Aim 2\n",
        "World Health Organization\n",
        "acute aortic dissection\n",
        "allogeneic bone marrow transplantation\n",
        "allogeneic stem cell transplantation\n",
        "breast cancer survivors\n",
        "chronic kidney disease\n",
        "chronic obstructive pulmonary disease\n",
        "daily 5 days\n",
        "fewer side effects\n",
        "final blood draw\n",
        "first 2 years\n",
        "health care costs\n",
        "health care providers\n",
        "health care system\n",
        "heart failure patients\n",
        "hepatic arterial infusion\n",
        "human immunodeficiency virus\n",
        "impaired glucose tolerance\n",
        "informed conse\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_chunk_gist(brown_news)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New York City\n",
        "La Dolce Vita\n",
        "home rule charter\n",
        "First Presbyterian Church\n",
        "Mrs. Robert O. Spurdle\n",
        "Philmont Country Club\n",
        "Richard J. Hughes\n",
        "South Viet Nam\n",
        "World War 2\n",
        "fire fighters association\n",
        "gas station man\n",
        "potato chip industry\n",
        "7:30 p.m. Sunday\n",
        "Air Force Academy\n",
        "April 4 ballot\n",
        "Armed Services Committee\n",
        "Atty. Gen. J. Joseph Nugent\n",
        "Carl W. Buchheister\n",
        "Central Falls City Council\n",
        "Cherry Hill Road\n",
        "Christian Youth Crusade\n",
        "Democratic gubernatorial nomination\n",
        "Diversified Growth Stock Fund\n",
        "Duncan Phyfe furniture\n",
        "Emory University's charter\n",
        "First Christian Church\n",
        "First Lady Jacqueline Kennedy\n",
        "G. David Thompson\n",
        "Henry Hall Wilson\n",
        "Highway Department source\n",
        "Holy Cross Hospital\n",
        "House Rules Committee\n",
        "Junior Achievement program\n",
        "Morton Foods stock issue\n",
        "Mr. Wendell Jr.\n",
        "Mrs. J. Clinton Bowman\n",
        "National Audubon Society\n",
        "National Christian Family Week\n",
        "National Football League\n",
        "National League club\n",
        "National Maintenance company\n",
        "New Eastwick Corp.\n",
        "New York State\n",
        "New York Yankees\n",
        "North Viet Nam\n",
        "Notre Dame Chapter\n",
        "Pinar Del Rio\n",
        "President John F. Kennedy\n",
        "President Kennedy today\n",
        "Prince Souvanna Phouma\n",
        "Rev. Mr. Brandt\n",
        "Rev. T. F. Zimmerman\n",
        "Rhode Island Hospital\n",
        "Sen. George Parkhouse\n",
        "Senate Foreign Relations Committee\n",
        "South Park Way\n",
        "St. Patrick's Day Purse\n",
        "State Highway Department\n",
        "Sunday sales laws\n",
        "U. S. Government\n",
        "United States Open\n",
        "W. H. Roquemore\n",
        "Washington State game\n",
        "due June 1\n",
        "first atomic submarine\n",
        "first three months\n",
        "international financial system\n",
        "last Saturday night\n",
        "last two days\n",
        "major Catholic institutions\n",
        "matching fund basis\n",
        "national Democratic party\n",
        "new school superintendent\n",
        "next 10 years\n",
        "nuclear test ban negotiations\n",
        "oil mill supplies\n",
        "parochial school system\n",
        "past few years\n",
        "public relations director\n",
        "public safety commissioner\n",
        "real estate agent\n",
        "sales tax bill\n",
        "sales tax measure\n",
        "social security payroll tax\n",
        "social security system\n",
        "state's occupation tax\n",
        "1 S. Dearborn St.\n",
        "1 billion dollars\n",
        "1% sales tax\n",
        "1,700 Johnston taxpayers\n",
        "1-1/2-story brick home\n",
        "1.23 million shares\n",
        "1.5 billion dollars\n",
        "10 Philadelphia area builders\n",
        "10 a.m. today\n",
        "10 a.m. tomorrow\n",
        "10 million dollar\n",
        "10 per cent\n",
        "10 witnesses yesterday\n",
        "10-year expansion program\n",
        "10-year-old safety patrol boy\n",
        "100,000 nonfiction volumes\n",
        "1020 Lawrence Av.\n",
        "1044 Chestnut Street\n",
        "10:45 a.m. Sunday service\n",
        "10:50 a.m. Sunday\n",
        "11 a.m. Sunday\n",
        "11:30 a.m. yesterday\n",
        "11:30 one night\n",
        "12 DeSoto St.\n",
        "12 semester hours\n",
        "12,000 babies born\n",
        "120 Cuban employees\n",
        "1200 Larimer St.\n",
        "1213 Walnut St.\n",
        "1213-15 Blue Island Av.\n",
        "1215 Blue Island Av.\n",
        "12th straight year\n",
        "13.5 millio\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_chunk_gist(mystery_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "U.S. Agriculture Department\n",
        "up 75 cts\n",
        "European currency units\n",
        "free market barley\n",
        "American Petroleum Institute\n",
        "Energy Information Administration\n",
        "International Monetary Fund\n",
        "contract barge customers\n",
        "four mln barrels\n",
        "weekly petroleum status report\n",
        "151 mln tonnes\n",
        "Finance Minister Kiichi Miyazawa\n",
        "Prime Minister Yasuhiro Nakasone\n",
        "contract barge price\n",
        "crude oil stocks\n",
        "major industrial nations\n",
        "two billion dlrs\n",
        "up one dlr\n",
        "1986/87 wheat crop\n",
        "500 mln dlrs\n",
        "Export Enhancement Program initiative\n",
        "International Coffee Organization\n",
        "U.S. Treasury Secretary James Baker\n",
        "crude oil prices\n",
        "past 12 months\n",
        "residual fuel demand\n",
        "residual fuel stocks\n",
        "senior ministry official\n",
        "up 50 cts\n",
        "13 pct moisture maximum\n",
        "18.53 billion dlrs\n",
        "25.65 billion dlrs\n",
        "3.04 billion dlrs\n",
        "3.5 mln barrels\n",
        "Energy Department agency\n",
        "FRENCH FREE MARKET CEREAL EXPORT BIDS DETAILED French operators\n",
        "Home Grown Cereals Authority\n",
        "Indian domestic market\n",
        "Lower House Budget Committee\n",
        "MAXIMUM REBATE 138.75 ECUS\n",
        "Metals Trading Corp\n",
        "Monday close 141.35\n",
        "One trade source\n",
        "State Trading Corp\n",
        "U.S. 1986/87 ENDING CORN STOCKS 5,240 MLN BU\n",
        "U.S. Agriculture Secretary Richard Lyng\n",
        "U.S. Farm products\n",
        "U.S. trade deficit\n",
        "WHEAT 1,848 MLN\n",
        "annual export earnings\n",
        "central bank intervention\n",
        "commerce ministry spokeswoman\n",
        "current fiscal year\n",
        "diesel gas oil\n",
        "easier monetary policy\n",
        "five mln dlrs\n",
        "just five pct\n",
        "money supply growth\n",
        "non-communist countertrade partners\n",
        "non-convertible Indian rupees\n",
        "one billion dlrs\n",
        "one mln tonnes\n",
        "one pct sulphur\n",
        "past several weeks\n",
        "three mln barrels\n",
        "two state trading corporations\n",
        "two state trading firms\n",
        "0.15 gm lead\n",
        "0.4 gm lead\n",
        "0.7 pct sulphur\n",
        "1.5 billion dlrs\n",
        "14 daps 24-27/4\n",
        "15 mln dlrs\n",
        "15.7 pct January rise\n",
        "150.5 mln tonnes\n",
        "16.39 mln barrels\n",
        "160 mln tonnes\n",
        "18.0 pct rise\n",
        "180 mln tonnes\n",
        "183 mln tonnes\n",
        "19.7 pct January rise\n",
        "2.2 pct sulphur\n",
        "2.5 billion dlrs\n",
        "250 mln dlrs\n",
        "29 mln tonnes\n",
        "31 pct devaluation\n",
        "393 mln dlrs\n",
        "4.2 pct rise\n",
        "50 pct interest\n",
        "8.38 mln bpd\n",
        "9.8 pct rise\n",
        "Chicago Mercantile Exchange\n",
        "Crude oil prices\n",
        "Domestic crude oil production\n",
        "Dunkirk/Xingang 12,000 mt\n",
        "EUROPEAN MARKETS REACT QUIETLY TO G-7 COMMUNIQUE European currency markets\n",
        "Federal Reserve Board chairman Paul Volcker\n",
        "Heating oil prices\n",
        "INDIA FOODGRAIN TARGET 160 MLN TONNES IN 1987/88 India\n",
        "International Coffee Organisation\n",
        "LONDON GRAIN FREIGHT ENQUIRIES Antwerp/Libya 5,500 mt\n",
        "Louis Dreyfus 5,300 tonnes\n",
        "MAIZE EXPORTS The European Commission\n",
        "Natural gas prices\n",
        "New Orleans/Guanta 9,387 mt bulk hss 3,000/13 days 25-4/5-5\n",
        "New York Mercantile Exchange\n",
        "New York \n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Frequent collocations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setting up measures"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
      "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procedure to calculate bi- and trigram collocations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collocate(tagged_text):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    '''\n",
      "    # trigrams first\n",
      "    finder = nltk.collocations.TrigramCollocationFinder.from_words([w for sent in tagged_text for w, t in sent])\n",
      "    finder.apply_freq_filter(5)\n",
      "    finder.apply_ngram_filter(lambda a, b, c: sum([1 for w in [a,c] if w.lower() in stopset]) > 0 or\n",
      "                              any([w[0] in punctuation for w in [a,b,c]]))\n",
      "    top_collocations = [' '.join(words) for words in finder.nbest(trigram_measures.pmi,50)]\n",
      "    \n",
      "    # then bigrams\n",
      "    finder = nltk.collocations.BigramCollocationFinder.from_words([w for sent in tagged_text for w, t in sent])\n",
      "    finder.apply_freq_filter(10)\n",
      "    finder.apply_word_filter(lambda w: w.lower() in stopset or w[0] in punctuation)\n",
      "    \n",
      "    # add top bigrams that aren't located in a top trigram\n",
      "    for bg in finder.nbest(bigram_measures.pmi,200):\n",
      "        fulltext = ' '.join(bg)\n",
      "        if not any([fulltext in tg for tg in top_collocations]): top_collocations.append(fulltext)\n",
      "    \n",
      "    return top_collocations\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wrapper procedure for printing the gist"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_collocate_gist(tagged_text):\n",
      "    '''\n",
      "    tagged_text: list of list of tuples, such as that returned by the pos_tag_text function\n",
      "    '''\n",
      "    print '\\n'.join(collocate(tagged_text))[:2500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Writing gists"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_collocate_gist(trial_desc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2,6 en SV\n",
        "peroxisome proliferator-activated receptor-alpha\n",
        "anti-MART-1 F5 TCR\n",
        "TMC207 po q.d\n",
        "Young Mania Rating\n",
        "Respiratory Syncytial Virus\n",
        "Mx-dnG1 retroviral vector\n",
        "hydromorphone HCI IR\n",
        "sentinel lymph node\n",
        "Canadian C-Spine Rule\n",
        "Beck Depression Inventory\n",
        "optical coherence tomography\n",
        "Visual Analogue Scale\n",
        "positron emission tomography\n",
        "polymerase chain reaction\n",
        "World Health Organization\n",
        "CTIS Pregnancy Health\n",
        "Mania Rating Scale\n",
        "calcium channel blockers\n",
        "M. D. Anderson\n",
        "1125 mg q12h\n",
        "Vi polysaccharide vaccine\n",
        "CT Head Rule\n",
        "displaced femoral neck\n",
        "Coronary Stent System\n",
        "omega-3 fatty acids\n",
        "unresectable hepatocellular carcinoma\n",
        "undisplaced femoral neck\n",
        "MenACWY conjugate vaccine\n",
        "magnetic resonance spectroscopy\n",
        "4-HPR/LXS oral powder\n",
        "DEC-205-NY-ESO-1 fusion protein\n",
        "ventricular ejection fraction\n",
        "Canadian CT Head\n",
        "Pregnancy Health Information\n",
        "external beam radiotherapy\n",
        "peer telephone cessation\n",
        "American Diabetes Association\n",
        "influenza A/H5N1 virus\n",
        "fluorine F 18\n",
        "angiotensin receptor blockers\n",
        "glomerular filtration rate\n",
        "Syncytial Virus infection\n",
        "non fatal myocardial\n",
        "fludeoxyglucose F 18\n",
        "resting energy expenditure\n",
        "forced vital capacity\n",
        "mg TMC207 po\n",
        "fatal myocardial infarction\n",
        "Depression Rating Scale\n",
        "Hong Kong\n",
        "sexually transmitted\n",
        "tramadol hydrochloride/acetaminophen\n",
        "H pylori\n",
        "OROS hydromorphone\n",
        "critically ill\n",
        "nitric oxide\n",
        "P. falciparum\n",
        "de novo\n",
        "epoetin alfa\n",
        "pemetrexed disodium\n",
        "telaprevir 750\n",
        "unfractionated heparin\n",
        "S. mutans\n",
        "BCG revaccination\n",
        "S. aureus\n",
        "green tea\n",
        "varying degrees\n",
        "imatinib mesylate\n",
        "barbed suture\n",
        "mm Hg\n",
        "allergic rhinitis\n",
        "Drug Administration\n",
        "MD Anderson\n",
        "DESIGN NARRATIVE\n",
        "fish oil\n",
        "lymph nodes\n",
        "atrial fibrillation\n",
        "atypical antipsychotic\n",
        "internal fixation\n",
        "minimally invasive\n",
        "counts recover\n",
        "umbilical cord\n",
        "cerebrospinal fluid\n",
        "operating room\n",
        "United States\n",
        "myeloid leukemia\n",
        "pulse wave\n",
        "computed tomography\n",
        "household members\n",
        "double blind\n",
        "African Americans\n",
        "gastric emptying\n",
        "knee arthroplasty\n",
        "leucovorin calcium\n",
        "doctor thinks\n",
        "optic nerve\n",
        "emergency department\n",
        "Courses repeat\n",
        "white matter\n",
        "multiple myeloma\n",
        "open label\n",
        "flow cytometry\n",
        "monoclonal antibody\n",
        "mineral density\n",
        "parenteral nutrition\n",
        "visual acuity\n",
        "folic acid\n",
        "animal models\n",
        "newly diagnosed\n",
        "mechanical ventilation\n",
        "laryngeal nerve\n",
        "phone call\n",
        "oxygen saturation\n",
        "gastric insufflation\n",
        "spinal cord\n",
        "erlotinib hydrochloride\n",
        "vital signs\n",
        "visual analogue\n",
        "PROJECTED ACCRUAL\n",
        "HDL cholesterol\n",
        "oxidative stress\n",
        "analogue scale\n",
        "Chinese medicine\n",
        "ventricular tachycardia\n",
        "transplant recipients\n",
        "Specific Aim\n",
        "central nervous\n",
        "sham acupuncture\n",
        "viral load\n",
        "1000 mg/m2\n",
        "smooth mus\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_collocate_gist(brown_news)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "home rule charter\n",
        "Assemblies of God\n",
        "10 per cent\n",
        "New York City\n",
        "four home runs\n",
        "Mr. Hawksley said\n",
        "Secretary of State\n",
        "Palmer and Player\n",
        "Mr. and Mrs.\n",
        "said he would\n",
        "Los Angeles\n",
        "San Francisco\n",
        "High School\n",
        "Premier Khrushchev\n",
        "U. S.\n",
        "anti-trust laws\n",
        "Kansas City\n",
        "vice president\n",
        "United States\n",
        "United Nations\n",
        "New Orleans\n",
        "White House\n",
        "American Catholic\n",
        "years ago\n",
        "sales tax\n",
        "high school\n",
        "President Kennedy\n",
        "last week\n",
        "last night\n",
        "Mrs. Robert\n",
        "last year\n",
        "Mr. Kennedy\n",
        "Mrs. John\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_collocate_gist(mystery_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Enhancement Program initiative\n",
        "Export Enhancement Program\n",
        "Energy Information Administration\n",
        "House Budget Committee\n",
        "discount window borrowings\n",
        "mt bagged flour\n",
        "Treasury Secretary James\n",
        "Commodity Credit Corporation\n",
        "Secretary Richard Lyng\n",
        "charges contract barge\n",
        "ranges broadly consistent\n",
        "Prime Minister Yasuhiro\n",
        "International Monetary Fund\n",
        "contract barge customers\n",
        "within ranges broadly\n",
        "weekly petroleum status\n",
        "0.4 gm lead\n",
        "Secretary James Baker\n",
        "WEEK Distillate fuel\n",
        "finished energy goods\n",
        "Minister Yasuhiro Nakasone\n",
        "International Coffee Organization\n",
        "BRUSSELS TRADE EC\n",
        "Brazilian Coffee Institute\n",
        "EC AUTHORISES EXPORT\n",
        "SAYS DISTILLATE STOCKS\n",
        "American Petroleum Institute\n",
        "Minister Kiichi Miyazawa\n",
        "Finance Minister Kiichi\n",
        "BANK OF JAPAN\n",
        "Singapore Pte Ltd\n",
        "API SAYS DISTILLATE\n",
        "intervened aggressively since\n",
        "Agriculture Secretary Richard\n",
        "petroleum status report\n",
        "Federal Reserve Board\n",
        "EIA SAYS DISTILLATE\n",
        "Distillate fuel stocks\n",
        "European currency units\n",
        "leading industrial nations\n",
        "Agreement on Tariffs\n",
        "past 12 months\n",
        "senior ministry official\n",
        "New York harbor\n",
        "dlrs FOB Gulf\n",
        "residual fuel demand\n",
        "annual export earnings\n",
        "contract barge price\n",
        "fell below 150\n",
        "close here yesterday\n",
        "Buenos Aires\n",
        "MONEY SUPPLY\n",
        "joint venture\n",
        "Saudi Arabia\n",
        "United States\n",
        "area sown\n",
        "dry weather\n",
        "Soviet Union\n",
        "92 octane\n",
        "97 octane\n",
        "European Community\n",
        "West Germany\n",
        "Louvre accord\n",
        "told Reuters\n",
        "USDA ESTIMATES\n",
        "first quarter\n",
        "money supply\n",
        "figures show\n",
        "coarse grain\n",
        "central bank\n",
        "MLN DLRS\n",
        "told reporters\n",
        "interest rates\n",
        "75 cts\n",
        "petroleum products\n",
        "unleaded gasoline\n",
        "Finance Ministry\n",
        "Agriculture Department\n",
        "per tonne\n",
        "effective today\n",
        "Paris accord\n",
        "calendar 1987\n",
        "central banks\n",
        "statement period\n",
        "feed wheat\n",
        "foreign exchange\n",
        "recent years\n",
        "ended March\n",
        "heating oil\n",
        "1986/87 coarse\n",
        "monetary policy\n",
        "pump prices\n",
        "year ago\n",
        "week ended\n",
        "per day\n",
        "number two\n",
        "wheat flour\n",
        "150 yen\n",
        "free market\n",
        "Crude oil\n",
        "soft wheat\n",
        "major nations\n",
        "last month\n",
        "crude oil\n",
        "oil companies\n",
        "currency markets\n",
        "trade deficit\n",
        "exchange rates\n",
        "Reserve Bank\n",
        "one dlr\n",
        "gasoline stocks\n",
        "U.S. Currency\n",
        "export quotas\n",
        "1986/87 season\n",
        "pct sulphur\n",
        "previous week\n",
        "55,000 tonnes\n",
        "fiscal year\n",
        "0.3 pct\n",
        "dollar opened\n",
        "billion dlrs\n",
        "January rise\n",
        "mln bushels\n",
        "0.5 pct\n",
        "ended April\n",
        "U.S. Agriculture\n",
        "mln bpd\n",
        "year earlier\n",
        "trade sources\n",
        "mln hectares\n",
        "prices rose\n",
        "mln barrels\n",
        "barrels per\n",
        "money market\n",
        "200,000 tonnes\n",
        "40 pct\n",
        "2.2 pct\n",
        "last year\n",
        "fuel oil\n",
        "rice production\n",
        "2.5 pct\n",
        "oil prices\n",
        "dollar fell\n",
        "wheat crop\n",
        "25 pct\n",
        "50 pct\n",
        "five pct\n",
        "last season\n",
        "10 pct\n",
        "oil stocks\n",
        "last week\n",
        "mln tonnes\n",
        "Conger said\n",
        "wheat exports\n",
        "trade official\n",
        "dlrs per\n",
        "department said\n",
        "sources\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Notes on algorithms and choices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### N-gram algorithm\n",
      "I wanted to do something more ambitious than a simple unigram or bigram frequency, and ended up with an algorithm that starts with a large n-gram (I found that 5-grams worked best for my corpus and Brown news), then gradually decreases the n-gram size, only keeping those frequently appearing n-grams that don't appear in a larger n-gram. The most frequent large n-grams appear far less often than the most frequent small n-grams, so the frequency threshold varied inversely proportional to n-gram size. The printed gist was ordered by a combination of n-gram size and frequency to address the same issue.\n",
      "\n",
      "This algorithm works surprisingly well in a variety of situations.\n",
      "\n",
      "#### Noun phrase chunking algorithm\n",
      "I tried a few different chunk definitions, and not just noun phrases, but felt that noun phrases gave the best gist of my corpus and Brown news. I originally had a determiner or possessive noun at the start of the chunk, but all those the's and this's were filling up my gist. I also added an optional adverb, since many important phrases in my corpus made more sense with the leading adverb (e.g. \"critically ill patients\"). Only chunks with three or more words are selected, and are ordered by frequency in the printed gist.\n",
      "\n",
      "This algorithm works best on my corpus and the mystery text.\n",
      "\n",
      "#### Collocation algorithm\n",
      "I endeavored to use both bigram and trigram collocations, in a manner similar to my n-gram algorithm: I started with the top 50 trigram collocations (that appeared more than 5 times), ordered by pointwise mutual information (PMI), then picked the top 100 bigram collocations (that appeared more than 10 times but were not contained in a selected trigram), also ordered by PMI. I did not allow trigrams to start or end with a stopword, and did not allow any stopwords in the bigrams. I tried a number of ranking measures and frequency thresholds, but this was about as good as I could get collocations.\n",
      "\n",
      "This algorithm works best on the Brown news corpus."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}