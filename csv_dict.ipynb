{
 "metadata": {
  "name": "",
  "signature": "sha256:3090e6efb2c09eed5ec94c6c8e33b41092ef2f5a4c0b1aa731f933c28ff7718d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "import nltk\n",
      "import re\n",
      "from collections import Counter\n",
      "from nltk import ne_chunk, pos_tag, word_tokenize\n",
      "from nltk import RegexpParser\n",
      "import nltk.chunk\n",
      "import itertools\n",
      "from nltk.tokenize import sent_tokenize\n",
      "import nltk.text\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "pd.set_option('max_columns', 50)\n",
      "from pandas.io import sql\n",
      "import functools\n",
      "import operator\n",
      "from functools import partial\n",
      "from nltk import ne_chunk, pos_tag, word_tokenize\n",
      "from nltk import RegexpParser\n",
      "import nltk.chunk\n",
      "import itertools\n",
      "from nltk.tokenize import sent_tokenize\n",
      "import nltk.text\n",
      "from functools import partial\n",
      "from string import punctuation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df = pd.read_csv('all_sentences_tagged_indexed__complete.csv', index_col=0,\n",
      "#                 dtype={'story_id': int, 'para_index': int, 'tagged_sent': object, 'quote_in_para': object})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import ast\n",
      "import csv\n",
      "import itertools\n",
      "from nltk import RegexpParser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Read CSV as Dict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_dict = []\n",
      "with open('all_sentences_tagged_indexed__complete.csv') as csvfile:\n",
      "    reader = csv.DictReader(csvfile)\n",
      "    for key, row in enumerate(reader):\n",
      "        data = {}\n",
      "        data['sent_index'] = key\n",
      "        data['story_id'] = int(row['story_id'])\n",
      "        data['para_index'] = int(row['para_index'])\n",
      "        data['tagged_sent'] = ast.literal_eval(row['tagged_sent'])\n",
      "        data['quote_in_para'] = row['quote_in_para']\n",
      "        df_dict.append(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### One document"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST_ARTICLE = []\n",
      "for data in df_dict:\n",
      "    if data['story_id'] == 13662:\n",
      "        TEST_ARTICLE.append(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def group_dict_func(list_of_dicts):\n",
      "    keyfunc = lambda x: x['para_index']\n",
      "    groups = []\n",
      "    data = sorted(list_of_dicts, key=keyfunc)\n",
      "    for k, g in itertools.groupby(data, key=keyfunc):\n",
      "        groups.append(list(g))\n",
      "\n",
      "    para_dict_list = []\n",
      "    for g in groups:\n",
      "        para_dict = {}\n",
      "        para_dict['tagged_sent'] = []\n",
      "        for l in g:\n",
      "            para_dict['para_index'] = l['para_index']\n",
      "            para_dict['quote_in_para'] = l['quote_in_para']\n",
      "            para_dict['story_id'] = l['story_id']\n",
      "            para_dict['tagged_sent'].append(l['tagged_sent'])\n",
      "        para_dict_list.append(para_dict)\n",
      "    \n",
      "    return para_dict_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "para_dict_TEST_ARTICLE = group_dict_func(TEST_ARTICLE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quote_grammar = '''\n",
      "NONQUOTE:   { <.*>+ } \n",
      "            } (<``>|<\\'\\'>) <.*>+ (<''>|<\\'\\'>) {\n",
      "            } (<``>|<\\'\\'>) <.*>+ (<''>|<\\'\\'>)? {\n",
      "            } (<``>|<\\'\\'>)? <.*>+ (<''>|<\\'\\'>) {\n",
      "\n",
      "QUOTE:      { (<``>|<\\'\\'>) <.*>+ (<''>|<\\'\\'>) }\n",
      "            { (<``>|<\\'\\'>) <.*>+ (<''>|<\\'\\'>)? }\n",
      "            { (<``>|<\\'\\'>)? <.*>+ (<''>|<\\'\\'>) }\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "last_para_index = len(para_dict_TEST_ARTICLE) - 1\n",
      "\n",
      "for paragraph in para_dict_TEST_ARTICLE:\n",
      "    if paragraph['para_index'] == 0 and paragraph['quote_in_para'] == 1:\n",
      "        print \"First paragraph\"\n",
      "        \n",
      "    elif paragraph['para_index'] == last_para_index and paragraph['quote_in_para'] == 1:\n",
      "        print \"Last paragraph\"\n",
      "\n",
      "    elif paragraph['quote_in_para'] == 1:\n",
      "        print \"Middle paragraph\"\n",
      "\n",
      "        '''capture nonquoted section in current paragraph'''\n",
      "        paragraph_quote_dict = {}\n",
      "        cp = RegexpParser(quote_grammar)\n",
      "        paragraph_sents = paragraph['tagged_sents'] # paragraph_sents = [s for s in paragraph['tagged_sent']]\n",
      "        nonquote_sents_in_paragraph = []\n",
      "        for sent in paragraph_sents:\n",
      "            tree = cp.parse(sent)\n",
      "            for key, subtree in enumerate(tree.subtrees()):\n",
      "                # first subtree in tree is S, so we remove to preserve indexing\n",
      "                if subtree.label() == 'QUOTE':\n",
      "                    paragraph_quote_dict[key-1] = subtree\n",
      "                if subtree.label() == 'NONQUOTE':\n",
      "                    paragraph_quote_dict[key-1] = subtree\n",
      "                    \n",
      "                    \n",
      "        '''look in nonquoted section of currenct paragraph'''\n",
      "        for key in paragraph_quote_dict.keys():\n",
      "            if paragraph_quote_dict[key]._label == 'NONQUOTE':\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-23-79853fc75aea>, line 28)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-79853fc75aea>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    if test_dict[key]._label == 'NONQUOTE':\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "line 6 above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#    for tags in tagged_sent_list:\n",
      "#        match_sent = [tags for text, pos in tags if text in ['said', 'Said']]\n",
      "#        d['feature_said_text'] = match_sent\n",
      "\n",
      "tuplist = [s for s in para_dict_TEST_ARTICLE[8]['tagged_sent']]\n",
      "for tup in tuplist:\n",
      "    matches = [tup for text, pos in tup if text == 'the']\n",
      "    if matches:\n",
      "        print matches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(u'``', u'``'), (u'If', u'IN'), (u'the', u'DT'), (u'federal', u'JJ'), (u'government', u'NN'), (u'has', u'VBZ'), (u'extra', u'JJ'), (u'resources', u'NNS'), (u'in', u'IN'), (u'Oakland', u'NNP'), (u',', u','), (u'then', u'RB'), (u'they', u'PRP'), (u'should', u'MD'), (u'use', u'VB'), (u'them', u'PRP'), (u'to', u'TO'), (u'get', u'VB'), (u'the', u'DT'), (u'illegal', u'JJ'), (u'guns', u'NNS'), (u'off', u'IN'), (u'the', u'DT'), (u'streets', u'NNS'), (u'that', u'WDT'), (u'are', u'VBP'), (u'actually', u'RB'), (u'killing', u'VBG'), (u'people', u'NNS'), (u',', u','), (u\"''\", u\"''\"), (u'Jason Overman', 'COREF'), (u'said', u'VBD'), (u'.', u'.')], [(u'``', u'``'), (u'If', u'IN'), (u'the', u'DT'), (u'federal', u'JJ'), (u'government', u'NN'), (u'has', u'VBZ'), (u'extra', u'JJ'), (u'resources', u'NNS'), (u'in', u'IN'), (u'Oakland', u'NNP'), (u',', u','), (u'then', u'RB'), (u'they', u'PRP'), (u'should', u'MD'), (u'use', u'VB'), (u'them', u'PRP'), (u'to', u'TO'), (u'get', u'VB'), (u'the', u'DT'), (u'illegal', u'JJ'), (u'guns', u'NNS'), (u'off', u'IN'), (u'the', u'DT'), (u'streets', u'NNS'), (u'that', u'WDT'), (u'are', u'VBP'), (u'actually', u'RB'), (u'killing', u'VBG'), (u'people', u'NNS'), (u',', u','), (u\"''\", u\"''\"), (u'Jason Overman', 'COREF'), (u'said', u'VBD'), (u'.', u'.')], [(u'``', u'``'), (u'If', u'IN'), (u'the', u'DT'), (u'federal', u'JJ'), (u'government', u'NN'), (u'has', u'VBZ'), (u'extra', u'JJ'), (u'resources', u'NNS'), (u'in', u'IN'), (u'Oakland', u'NNP'), (u',', u','), (u'then', u'RB'), (u'they', u'PRP'), (u'should', u'MD'), (u'use', u'VB'), (u'them', u'PRP'), (u'to', u'TO'), (u'get', u'VB'), (u'the', u'DT'), (u'illegal', u'JJ'), (u'guns', u'NNS'), (u'off', u'IN'), (u'the', u'DT'), (u'streets', u'NNS'), (u'that', u'WDT'), (u'are', u'VBP'), (u'actually', u'RB'), (u'killing', u'VBG'), (u'people', u'NNS'), (u',', u','), (u\"''\", u\"''\"), (u'Jason Overman', 'COREF'), (u'said', u'VBD'), (u'.', u'.')]]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "person_said_rule = '''\n",
      "QT:\n",
      "    { (<``>|<\\'\\'>)+ <.*>+ (<''>|<\\'\\'>)+ <.*>+ }\n",
      "    } (<``>|<\\'\\'>)+ <.*>+ (<''>|<\\'\\'>) {\n",
      "    { <VB>+ <DT>?<NNP>+<JJ.*>*<RB>? <JJ.*>*<NN.*|CD>* }\n",
      "    } <VB.*> {\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for p in para_dict_13661:\n",
      "#    sents = p['tagged_sent']\n",
      "\n",
      "test_dict = {}\n",
      "paragraph = para_dict_TEST_ARTICLE[8]['tagged_sent']\n",
      "cp = RegexpParser(quote_grammar)\n",
      "nonquote_sents_in_paragraph = []\n",
      "for sent in paragraph:\n",
      "    tree = cp.parse(sent)\n",
      "    for key, subtree in enumerate(tree.subtrees()):\n",
      "        '''first subtree in tree is S, so we remove to preserve indexing\n",
      "        dictionary key is the order of the QUOTE/NONQUOTE areas of the paragraph'''\n",
      "        if subtree.label() == 'QUOTE':\n",
      "            test_dict[key-1] = subtree\n",
      "        if subtree.label() == 'NONQUOTE':\n",
      "            test_dict[key-1] = subtree\n",
      "\n",
      "                #words =  [word[0] for word in subtree]\n",
      "                #words = \" \".join(words)\n",
      "                #print words\n",
      "\n",
      "for key in test_dict.keys():\n",
      "    if test_dict[key]._label == 'NONQUOTE':\n",
      "        print test_dict[key].leaves()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Jason Overman', 'COREF'), (u'said', u'VBD'), (u'.', u'.')]\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_dict[1]._label"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NONQUOTE\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}